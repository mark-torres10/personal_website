---
layout: single
title:  "Why I'm not too worried about AI taking over the world"
date:   2024-05-16 05:00:00 +0800
classes: wide
toc: true
categories:
- personal
- all_posts
permalink: /personal/2024-05-18-ai-thoughts
---

# Why I'm not too worried about AI taking over the world
[stuff stuff]

I'm currently reading Nick Bostrom's classic book [Superintelligence](https://www.goodreads.com/en/book/show/20527133), and my thoughts could change based on how he describes the future of AGI and our relationship with it. It's definitely in the science-fiction/transhumanist camp, which I think applies to a very niche effective-altruist subset of people, but there's a high overlap between that group and Silicon Valley.

## Some concerns about AI that I think are valid
- Access to WMD, other warfare-related uses
- Use by malicious state actors
- Lowering the cost of phishing attacks, identity fraud, and other scams related to social engineering
- Propagation of misinformation

## My reasons for not worrying about AI in general

### If AI exceeded human intelligence, how would we know? And would we believe it?

### AI adoption is left as an exercise to the reader
[great at building stuff, not adapting it in practice]

[so much enterprise tech still revolves around combinations of Excel, VBA, and people coding stuff up. That's why so many startups can come in and try to fix "enterprise problems" even though AI exists]

[most companies arguably don't even have the data infrastructure required to do AI in the first place]

[lots of value is currently locked in proprietary databases]

[applying AI to areas of high reach, like corporations, govt, etc., face so many non-technical hurdles, such as regulation, paperwork, the whims of the C-suite, etc.]

For example, a large chunk of Wall Street has been [grappling with](https://finance.yahoo.com/news/wall-street-cobol-cowboys-spread-105830995.html) having to migrate their legacy codebases away from COBOL code written in the 1960s to something more modern and compliant. Many companies such as IBM have been [hard at work](https://www.ciodive.com/news/banks-leverage-generative-AI-cobol-coding-assistants/703988/) using Generative AI to migrate COBOL to more modern systems like Java, but that is not a straightforward task by any means. As anyone who has done a nontrivial migration of either a codebase or a database knows, a migration can be one of the most stressful but ill-rewarded things you can do as an engineer. Your job is to make sure that one system is migrated to another, all while ensuring that current systems are still operational in-real-time, all while testing that the current fix goes right, all while making sure to have backups in place the switch from the old to new system breaks. [This](https://www.alibabacloud.com/tech-news/a/database_migration/guh6vm4vpd-migration-war-stories-when-database-moves-go-wrong) blog and [this](https://www.consegna.cloud/news/cloud-migration-war-stories/) blog both describe in more detail what these "horror story" experiences can be; they really can be watershed moments in the maturation of a software engineer.

### Advancing the frontiers != advancing all of humanity
[stuff]

There's this implicit assumption that by working on better AI models or creating self-driving cars or cryptocurrencies or whatever frontier projects Silicon Valley overhypes, that this will somehow lead to "the betterment of all humanity". This techno-optimism is so deeply ingrained in Silicon Valley tech culture and reinforced by the mountains of capital and human talent pushed towards these projects.

#### Self-driving cars
Let's take self-driving cars for example.

#### Financial applications
[something something new Silicon Valley startups, Stripe, etc.]

[large bits of the world unbanked]

[large bits of the world operate on cash]

### There are plenty of problems left to be fixed that don't require "Generative AI"

#### Simple, impactful uses of "classical" (i.e., "boring") AI

There is this platform called [DrivenData](https://www.drivendata.org/).

## What I am more worried about instead
There are many problems in the world that I find more worrying than any thoughts about AI apocalypse or "AI eating the world"

# Conclusion
I'm very pro-progress. I love tech, I love working in AI as an engineer, and I think that working on AI for frontier applications does, on net, lead to general advancement. But I also think that the general ethos of "advancing all humanity" by hyperfixating on Silicon Valley's latest pet projects is disingenuous, short-sighted, and really only serves to exacerbate already-existing divides between the West and the Global South.
