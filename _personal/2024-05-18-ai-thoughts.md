---
layout: single
title:  "Why I'm not too worried about AI taking over the world"
date:   2024-05-16 05:00:00 +0800
classes: wide
toc: true
categories:
- personal
- all_posts
permalink: /personal/2024-05-18-ai-thoughts
---

# Why I'm not too worried about AI taking over the world
[stuff stuff]

I'm currently reading Nick Bostrom's classic book [Superintelligence](https://www.goodreads.com/en/book/show/20527133), and my thoughts could change based on how he describes the future of AGI and our relationship with it. It's definitely in the science-fiction/transhumanist camp, which I think applies to a very niche effective-altruist subset of people, but there's a high overlap between that group and Silicon Valley.

## Some concerns about AI that I think are valid
- Access to WMD, other warfare-related uses
- Use by malicious state actors
- Lowering the cost of phishing attacks, identity fraud, and other scams related to social engineering
- Propagation of misinformation

## My reasons for not worrying about AI in general

### If AI exceeded human intelligence, how would we know? And would we believe it?

### Advancing the frontiers != advancing all of humanity
[stuff]

There's this implicit assumption that by working on better AI models or creating self-driving cars or cryptocurrencies or whatever frontier projects Silicon Valley overhypes, that this will somehow lead to "the betterment of all humanity". This techno-optimism is so deeply ingrained in Silicon Valley tech culture and reinforced by the mountains of capital and human talent pushed towards these projects.

#### Self-driving cars
Let's take self-driving cars for example.

#### Financial applications
[something something new Silicon Valley startups, Stripe, etc.]

[large bits of the world unbanked]

[large bits of the world operate on cash]

### There are plenty of problems left to be fixed that don't require "Generative AI"

#### Simple, impactful uses of "classical" (i.e., "boring") AI

There is this platform called [DrivenData](https://www.drivendata.org/).

## What I am more worried about instead
There are many problems in the world that I find more worrying than any thoughts about AI apocalypse or "AI eating the world"

# Conclusion
I'm very pro-progress. I love tech, I love working in AI as an engineer, and I think that working on AI for frontier applications does, on net, lead to general advancement. But I also think that the general ethos of "advancing all humanity" by hyperfixating on Silicon Valley's latest pet projects is disingenuous, short-sighted, and really only serves to exacerbate already-existing divides between the West and the Global South.
